{
  "cells": [
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "#### The following steps would help you get started. To **RUN THIS CODE HERE**, you need to *fork* a new branch (see the blue button on the top-right corner), and then execute each cell by pressing *Shift+Enter* or clicking on the blue botton on the left side of each cell.\n\n* Let\u0027s import a few handy toolds."
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom json import JSONDecoder, JSONDecodeError  # for reading the JSON data files\nimport re  # for regular expressions\nimport os  # for os related operations",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "Input data files are available in the \u0027../input/\u0027 directory.\nAny results you write to the current directory will be saved here as output.\n\n* We can list all files in this directory:"
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "print(os.listdir(\"../input\"))",
      "execution_count": 7,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m\u003cipython-input-7-b8e5fd5020e3\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[0;34m\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \u0027../input\u0027"
          ],
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: \u0027../input\u0027",
          "output_type": "error"
        }
      ]
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* To be able to read the data in json format, we need to have a decoder as follows:"
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "def decode_obj(line, pos\u003d0, decoder\u003dJSONDecoder()):\n    no_white_space_regex \u003d re.compile(r\u0027[^\\s]\u0027)\n    while True:\n        match \u003d no_white_space_regex.search(line, pos)\n        if not match:\n            return\n        pos \u003d match.start()\n        try:\n            obj, pos \u003d decoder.raw_decode(line, pos)\n        except JSONDecodeError as err:\n            print(\u0027Oops! something went wrong. Error: {}\u0027.format(err))\n        yield obj",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* As an example, let\u0027s implement a method that gets the last values of a multi-variate time series corresponding to each observation window."
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "def get_obj_with_last_n_val(line, n):\n    obj \u003d next(decode_obj(line))  # type:dict\n    id \u003d obj[\u0027id\u0027]\n    class_label \u003d obj[\u0027classNum\u0027]\n\n    data \u003d pd.DataFrame.from_dict(obj[\u0027values\u0027])  # type:pd.DataFrame\n    data.set_index(data.index.astype(int), inplace\u003dTrue)\n    last_n_indices \u003d np.arange(0, 60)[-n:]\n    data \u003d data.loc[last_n_indices]\n\n    return {\u0027id\u0027: id, \u0027classType\u0027: class_label, \u0027values\u0027: data}",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* The above methods allow us to load the data as Pandas.DataFrame, or even save them in CSV format. Let\u0027s define a new method that does this. Note that you can uncomment the part that stores the data in CSV format if you want."
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "\ndef convert_json_data_to_csv(data_dir: str, file_name: str):\n    \"\"\"\n    Generates a dataframe by concatenating the last values of each\n    multi-variate time series. This method is designed as an example\n    to show how a json object can be converted into a csv file.\n    :param data_dir: the path to the data directory.\n    :param file_name: name of the file to be read, with the extension.\n    :return: the generated dataframe.\n    \"\"\"\n    fname \u003d os.path.join(data_dir, file_name)\n\n    all_df, labels, ids \u003d [], [], []\n    with open(fname, \u0027r\u0027) as infile: # Open the file for reading\n        for line in infile:  # Each \u0027line\u0027 is one MVTS with its single label (0 or 1).\n            obj \u003d get_obj_with_last_n_val(line, 1)\n            all_df.append(obj[\u0027values\u0027])\n            labels.append(obj[\u0027classType\u0027])\n            ids.append(obj[\u0027id\u0027])\n\n    df \u003d pd.concat(all_df).reset_index(drop\u003dTrue)\n    df \u003d df.assign(LABEL\u003dpd.Series(labels))\n    df \u003d df.assign(ID\u003dpd.Series(ids))\n    df.set_index([pd.Index(ids)])\n    # Uncomment if you want to save this as CSV\n    # df.to_csv(file_name + \u0027_last_vals.csv\u0027, index\u003dFalse)\n    return df",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* Now we are ready to load data. We try loading \u0027fold3Training.json\u0027 as an example. This should result in a dataframe with 27006 rows and 27 columns (i.e., all 25 physical parameters, plus two additional columns: ID and LABEL)"
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "path_to_data \u003d \"./input\"\nfile_name \u003d \"fold3Training.json\"\n\ndf \u003d convert_json_data_to_csv(path_to_data, file_name)  # shape: 27006 X 27\nprint(\u0027df.shape \u003d {}\u0027.format(df.shape))\n# print(list(df))\nprint(df)",
      "execution_count": 14,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "df.shape \u003d (27006, 27)\n           TOTUSJH        TOTBSQ        TOTPOT       TOTUSJZ      ABSNJZH  \\\n0      2279.058608  4.176910e+10  6.722922e+23  4.151445e+13   298.753182   \n1       324.136602  3.044442e+09  1.842963e+22  7.596014e+12    64.312903   \n2        90.928971  6.418759e+08  5.420498e+21  1.975487e+12     0.886584   \n3       173.008586  2.210899e+09  2.422310e+22  3.389141e+12    10.262131   \n4        56.286406  3.814089e+08  2.659824e+21  1.210523e+12     8.744935   \n5        19.279922  1.569373e+08  1.154881e+21  4.398508e+11     1.149915   \n6       769.412439  1.176934e+10  1.999628e+23  1.795664e+13    88.269954   \n7       183.011264  1.274385e+09  8.443752e+21  3.505530e+12     9.407660   \n8        15.650825  1.194461e+08  8.034953e+20  3.348638e+11     1.961768   \n9       343.409575  5.359117e+09  9.470372e+22  7.374356e+12    59.548721   \n10     2940.076791  2.753561e+10  5.259057e+23  5.326476e+13   578.557954   \n11     2956.525273  3.766238e+10  5.248393e+23  5.886684e+13   102.022213   \n12      566.952529  4.362286e+09  3.674841e+22  1.177312e+13     4.362699   \n13        3.996232  2.238200e+07  1.635523e+20  1.032164e+11     0.222586   \n14      290.729186  7.690949e+09  1.586642e+23  6.852974e+12    54.264720   \n15       57.298489  3.903787e+08  2.749189e+21  1.246819e+12     0.367786   \n16       20.582076  1.626985e+08  1.210418e+21  4.838728e+11     0.813378   \n17     1755.542973  2.892143e+10  4.276857e+23  3.587123e+13   102.830160   \n18       35.559283  2.705701e+08  1.915623e+21  8.512585e+11     1.773228   \n19       29.604021  1.666798e+08  1.350665e+21  7.019867e+11     4.339073   \n20      421.686748  3.489511e+09  3.346547e+22  8.588919e+12    10.351252   \n21      157.205703  4.926049e+09  9.325401e+22  3.608749e+12    13.741180   \n22       44.446921  3.147697e+08  2.157131e+21  1.020152e+12     0.554917   \n23       30.908756  2.304377e+08  1.867991e+21  7.393588e+11     4.591007   \n24      452.387350  3.552658e+09  3.144031e+22  1.066089e+13     5.718001   \n25      399.380369  6.386332e+09  6.540989e+22  6.696721e+12    29.482595   \n26     2333.280607  3.691621e+10  6.858060e+23  5.308310e+13   286.511063   \n27     1211.007996  2.127533e+10  3.983241e+23  2.605411e+13   170.275147   \n28     7980.668961  1.171766e+11  2.382375e+24  1.208034e+14  1501.438802   \n29       17.419489  9.723026e+07  6.961647e+20  4.376079e+11     1.531053   \n...            ...           ...           ...           ...          ...   \n26976    52.085482  5.034115e+08  3.038047e+21  1.248401e+12     4.759184   \n26977    49.758249  3.513472e+08  3.835465e+21  1.306867e+12     1.372393   \n26978    26.487688  1.753586e+08  1.298404e+21  6.253700e+11     1.074887   \n26979   762.343138  1.022028e+10  1.286515e+23  1.577025e+13   147.143699   \n26980   604.330472  5.962291e+09  8.565954e+22  1.148660e+13   211.208333   \n26981     5.210922  2.919656e+07  1.516943e+20  1.144169e+11     3.085684   \n26982   458.332727  5.099755e+09  5.790855e+22  9.610623e+12    74.733426   \n26983    88.656639  6.833241e+08  5.760955e+21  2.023658e+12     3.907855   \n26984    67.567877  5.126129e+08  3.594120e+21  1.374173e+12    10.192856   \n26985   331.729305  5.221694e+09  7.225179e+22  6.553850e+12    45.149489   \n26986    43.250424  3.040266e+08  1.974152e+21  9.117272e+11     1.786123   \n26987  1620.090129  2.165144e+10  3.176305e+23  3.539637e+13    84.384379   \n26988     7.136702  4.478652e+07  1.534052e+20  1.565079e+11     1.193544   \n26989   650.165059  5.042242e+09  4.779653e+22  1.450264e+13    33.766481   \n26990  3739.081541  4.970842e+10  6.166037e+23  6.592116e+13   197.912595   \n26991    71.566756  6.290053e+08  5.404058e+21  1.223036e+12     6.383374   \n26992   624.761244  4.056380e+09  3.712431e+22  1.323122e+13    86.826066   \n26993    26.379833  1.597184e+08  1.418011e+21  6.362347e+11     6.632427   \n26994    88.150048  5.580511e+08  4.085251e+21  1.946991e+12     9.717471   \n26995  3162.523203  4.341540e+10  6.655205e+23  5.678595e+13   117.828525   \n26996   560.485363  4.758706e+09  4.844430e+22  1.186745e+13    26.792192   \n26997    26.138170  1.835495e+08  1.368651e+21  5.863703e+11     3.965502   \n26998    96.378134  8.017439e+08  7.273721e+21  1.741900e+12     4.202549   \n26999    46.506688  2.783675e+08  2.407929e+21  1.202262e+12     7.262990   \n27000    63.216932  4.244294e+08  3.606690e+21  1.608132e+12     8.284784   \n27001   171.735283  1.527383e+09  1.056428e+22  3.740316e+12    23.732638   \n27002          NaN           NaN           NaN           NaN          NaN   \n27003  1499.427995  2.038154e+10  3.498999e+23  3.312639e+13   183.984754   \n27004    45.838965  3.447708e+08  2.578061e+21  1.038143e+12     2.639830   \n27005    59.017049  5.413592e+08  3.036725e+21  1.098524e+12     0.180192   \n\n            SAVNCPP        USFLUX         TOTFZ       MEANPOT      EPSZ  ...  \\\n0      1.443831e+13  4.253660e+22 -1.714706e+25   8492.605611 -0.309116  ...   \n1      3.644793e+12  6.458115e+21 -2.912557e+24   1274.079337 -0.720368  ...   \n2      2.427102e+11  1.151176e+21 -4.688949e+23   2220.655208 -0.550062  ...   \n3      5.886247e+11  2.174629e+21 -9.750141e+23   5685.685977 -0.332070  ...   \n4      4.558530e+11  5.944778e+20 -2.321260e+23   2002.813020 -0.458269  ...   \n5      1.393471e+11  3.224133e+20 -1.334484e+23   1678.784190 -0.640287  ...   \n6      6.052294e+12  1.093841e+22 -3.276327e+24   8586.789917 -0.209615  ...   \n7      5.339763e+11  1.769230e+21 -7.431136e+23   2359.196507 -0.439078  ...   \n8      2.205598e+11  2.066911e+20 -8.663766e+22   1878.948978 -0.546163  ...   \n9      2.578021e+12  4.465621e+21 -9.899155e+23   9437.623499 -0.139089  ...   \n10     1.782511e+13  2.166460e+22 -3.703326e+24  10628.307528 -0.101271  ...   \n11     6.286745e+12  3.936303e+22 -1.694152e+25   6715.444513 -0.338713  ...   \n12     7.760679e+12  6.489257e+21 -2.801372e+24   2685.990388 -0.483553  ...   \n13     1.285950e+09  5.535713e+19 -1.743930e+22   1129.841539 -0.586702  ...   \n14     2.756010e+12  4.844962e+21 -7.645069e+23  15811.558019 -0.074850  ...   \n15     4.574823e+11  7.350583e+20 -3.055225e+23   1726.525116 -0.589311  ...   \n16     2.692130e+10  3.350816e+20 -1.355375e+23   1582.341689 -0.627283  ...   \n17     3.051161e+12  3.034728e+22 -1.272375e+25   7077.063420 -0.331271  ...   \n18     1.503406e+11  5.708115e+20 -2.334995e+23   1476.396651 -0.649821  ...   \n19     4.212780e+11  3.485644e+20 -1.349964e+23   1692.234346 -0.609855  ...   \n20     1.606051e+12  4.844957e+21 -2.215176e+24   3332.328150 -0.478004  ...   \n21     6.609197e+11  3.449614e+21 -8.955873e+23  13749.567142 -0.136898  ...   \n22     5.704518e+10  6.398970e+20 -2.441172e+23   1520.871959 -0.583973  ...   \n23     3.847189e+11  4.730872e+20 -1.901558e+23   1762.622987 -0.621360  ...   \n24     5.775389e+11  6.543593e+21 -2.767043e+24   2148.484255 -0.586476  ...   \n25     1.066527e+12  7.328107e+21 -4.103857e+24   5167.643049 -0.483870  ...   \n26     1.091463e+13  3.295867e+22 -7.970651e+24   9274.646594 -0.162579  ...   \n27     7.956563e+12  1.753585e+22 -5.050475e+24  11400.821944 -0.178749  ...   \n28     3.601948e+13  8.194002e+22 -2.060538e+25  16004.653805 -0.132412  ...   \n29     1.732695e+11  2.235483e+20 -7.856005e+22   1291.140515 -0.608398  ...   \n...             ...           ...           ...           ...       ...  ...   \n26976  1.654227e+11  1.146366e+21 -4.889919e+23   1193.951214 -0.731419  ...   \n26977  5.511708e+11  4.987482e+20 -1.939251e+23   2737.493038 -0.415609  ...   \n26978  8.289448e+10  3.725180e+20 -1.436641e+23   1511.099313 -0.616891  ...   \n26979  4.538050e+12  1.251677e+22 -5.443352e+24   5137.241320 -0.401043  ...   \n26980  8.973309e+12  5.223488e+21 -1.955177e+24   8125.538501 -0.246922  ...   \n26981  1.857873e+11  5.567683e+19 -1.866910e+22   1202.356090 -0.481481  ...   \n26982  4.304984e+12  6.683635e+21 -3.006367e+24   4287.550419 -0.443895  ...   \n26983  3.648269e+11  1.376601e+21 -5.570741e+23   1951.382934 -0.613866  ...   \n26984  6.338801e+11  8.097018e+20 -3.648714e+23   2216.482313 -0.535967  ...   \n26985  1.980725e+12  4.867614e+21 -2.090885e+24   7659.389985 -0.301513  ...   \n26986  1.546336e+11  5.349844e+20 -2.478953e+23   1835.198505 -0.613966  ...   \n26987  3.455068e+12  2.564331e+22 -9.313274e+24   5697.547195 -0.323894  ...   \n26988  1.493568e+11  8.714507e+19 -3.495002e+22    831.022638 -0.587608  ...   \n26989  6.857215e+12  7.250491e+21 -2.930887e+24   2839.460652 -0.437686  ...   \n26990  5.403637e+12  5.791243e+22 -2.888074e+25   5952.036700 -0.437488  ...   \n26991  4.931763e+11  6.438894e+20 -2.941676e+23   4645.189608 -0.352150  ...   \n26992  4.568280e+12  6.453313e+21 -2.784077e+24   2656.225553 -0.516809  ...   \n26993  4.601937e+11  3.491301e+20 -1.311229e+23   1779.573054 -0.618175  ...   \n26994  6.154127e+11  1.093340e+21 -4.308602e+23   1731.086489 -0.581366  ...   \n26995  8.512659e+12  4.005325e+22 -1.740505e+25   9233.303946 -0.301869  ...   \n26996  3.372489e+12  5.927618e+21 -2.349033e+24   3764.492071 -0.371696  ...   \n26997  3.257205e+11  3.691170e+20 -1.446319e+23   1612.795328 -0.593333  ...   \n26998  3.695232e+11  9.457313e+20 -4.513114e+23   4057.050995 -0.423866  ...   \n26999  4.124293e+11  6.025150e+20 -2.068675e+23   1590.473080 -0.559579  ...   \n27000  7.670624e+11  9.112248e+20 -3.485755e+23   1670.228010 -0.618413  ...   \n27001  1.468685e+12  2.980663e+21 -1.340323e+24   1688.193479 -0.660768  ...   \n27002           NaN           NaN           NaN           NaN       NaN  ...   \n27003  1.011388e+13  1.794865e+22 -4.397726e+24   8509.464169 -0.162472  ...   \n27004  3.466830e+11  7.130180e+20 -2.911130e+23   1664.876896 -0.635797  ...   \n27005  1.446162e+11  9.293353e+20 -5.009208e+23   1760.288278 -0.696740  ...   \n\n              TOTFY   MEANJZD   MEANALP         TOTFX      EPSY      EPSX  \\\n0     -9.851233e+23 -0.063377  0.010927  5.139045e+24  0.017759 -0.092643   \n1      1.059818e+23 -0.255003  0.024558  9.967036e+23 -0.026213 -0.246516   \n2     -1.457803e+23  0.256968  0.001782  2.034861e+23  0.171015 -0.238710   \n3     -1.981958e+23  0.358722 -0.006969  3.362239e+22  0.067501 -0.011451   \n4     -1.028025e+23  0.881417  0.031445 -6.666904e+22  0.202955  0.131620   \n5     -5.439190e+22 -0.514683  0.008934  4.020031e+22  0.260973 -0.192881   \n6     -7.384541e+23  0.301011 -0.012401 -1.333994e+24  0.047245  0.085347   \n7     -2.300791e+23  0.304554  0.010260 -9.067462e+22  0.135945  0.053576   \n8     -2.292573e+22  1.306809  0.021245 -4.321268e+22  0.144524  0.272412   \n9     -2.026672e+23  0.548161 -0.019510 -2.710152e+23  0.028476  0.038079   \n10    -5.756769e+23  0.309473 -0.038158  1.668298e+24  0.015742 -0.045621   \n11    -1.235402e+24 -0.210004 -0.004047 -6.593009e+24  0.024699  0.131815   \n12     8.295814e+23  1.442954  0.001348 -2.477560e+23 -0.143196  0.042766   \n13    -6.801552e+21  0.023079 -0.012535  7.017628e+21  0.228821 -0.236091   \n14    -1.352618e+23  0.589544  0.013129 -1.449262e+23  0.013243  0.014189   \n15    -1.480134e+23  0.734554 -0.001186 -5.106781e+22  0.285498  0.098503   \n16    -2.510305e+22  0.091566 -0.006144 -6.124082e+22  0.116180  0.283429   \n17    -1.167714e+24 -0.053039  0.005342  4.195460e+24  0.030402 -0.109231   \n18    -5.059111e+22  0.302654 -0.007945  9.732765e+22  0.140793 -0.270859   \n19     6.336321e+22  1.360269 -0.032341  2.699407e+22 -0.286247 -0.121947   \n20     5.779751e+23  0.231732  0.004014  7.009968e+23 -0.124719 -0.151265   \n21    -2.926441e+23 -0.022380  0.004907  3.238433e+23  0.044733 -0.049502   \n22     2.231465e+22  0.102773  0.002226 -1.230958e+23 -0.053381  0.294468   \n23    -6.571219e+22  0.943425  0.024576  6.488952e+22  0.214724 -0.212035   \n24     3.229420e+23  0.015537  0.002029  1.183968e+24 -0.068448 -0.250942   \n25     4.777043e+22 -0.144062 -0.006222 -9.274777e+23 -0.005632  0.109355   \n26    -1.558703e+24  0.384410  0.013352  2.110066e+24  0.031793 -0.043039   \n27     1.546471e+24  0.580672 -0.013579  1.000490e+24 -0.054733 -0.035410   \n28    -3.992084e+23  0.283740 -0.022630 -1.111928e+25  0.002565  0.071453   \n29    -1.657952e+22 -0.586459  0.019581  3.604324e+22  0.128398 -0.279132   \n...             ...       ...       ...           ...       ...       ...   \n26976 -2.009312e+22 -0.169091  0.010920  1.827661e+23  0.030055 -0.273376   \n26977 -1.273373e+23  1.021760 -0.005519 -3.476162e+21  0.272902  0.007450   \n26978 -5.957942e+22  0.251962  0.007582 -4.249374e+22  0.255833  0.182467   \n26979 -4.512104e+23  0.150879  0.020553 -1.950143e+24  0.033243  0.143678   \n26980 -1.836907e+23  0.175939  0.056818 -1.010648e+24  0.023199  0.127636   \n26981  1.126754e+22 -3.844277 -0.142677 -4.083524e+21 -0.290593  0.105315   \n26982  2.703560e+23  0.531483 -0.020298  1.067170e+24 -0.039918 -0.157569   \n26983 -1.805467e+23  0.319209  0.007087  2.253163e+23  0.198953 -0.248287   \n26984 -1.474473e+23  0.943643  0.025891 -1.153179e+23  0.216588  0.169393   \n26985 -4.673730e+23  0.458703  0.013287 -8.308561e+23  0.067397  0.119812   \n26986  1.048126e+23  0.372603  0.007280 -2.741490e+22 -0.259591  0.067899   \n26987 -1.614228e+24  0.159055  0.005888 -3.684538e+24  0.056139  0.128140   \n26988  2.337422e+20  2.111413  0.033572  9.233029e+21 -0.003930 -0.155233   \n26989  9.826942e+23  1.037025  0.009285  9.077460e+22 -0.146751 -0.013556   \n26990 -1.075987e+24 -0.136231  0.005540 -9.320666e+24  0.016299  0.141190   \n26991 -5.059559e+22 -0.055782  0.015011  1.684866e+21  0.060568 -0.002017   \n26992  5.233204e+23  0.004682  0.028223  1.134823e+24 -0.097144 -0.210657   \n26993  4.191435e+22 -1.492837  0.051324  5.727869e+22 -0.197604 -0.270039   \n26994  1.928694e+23  0.677265 -0.022023  1.438913e+23 -0.260242 -0.194155   \n26995 -1.511407e+24 -0.308187  0.004169 -6.641933e+24  0.026213  0.115196   \n26996 -3.279394e+23  0.679815 -0.008209  4.296374e+23  0.051891 -0.067983   \n26997  6.494357e+21  0.991010  0.027119 -7.439327e+22 -0.026642  0.305188   \n26998 -2.230050e+22  0.374190  0.007363  1.710585e+23  0.020944 -0.160656   \n26999 -3.375614e+22  0.711073  0.033460  1.119075e+23  0.091311 -0.302711   \n27000  6.701639e+22  0.537095  0.024122  1.655711e+23 -0.118895 -0.293742   \n27001  2.017276e+23  0.290499 -0.018712 -5.126828e+23 -0.099450  0.252748   \n27002           NaN       NaN       NaN           NaN       NaN       NaN   \n27003 -9.404306e+23  0.226914 -0.015531  9.360681e+23  0.034744 -0.034583   \n27004 -1.380138e+23  0.576213  0.009362  4.456315e+22  0.301425 -0.097327   \n27005 -5.866173e+21 -0.218324  0.000392  1.589530e+23  0.008159 -0.221091   \n\n        R_VALUE        XR_MAX  LABEL     ID  \n0      4.961807  9.983000e-07      1      1  \n1      2.148500  1.639000e-06      0      2  \n2      0.000000  7.887100e-07      0      3  \n3      0.000000  6.365600e-07      0      4  \n4      2.438045  7.756200e-07      0      5  \n5      0.000000  6.100600e-07      0      6  \n6      3.811586  3.779100e-06      0      7  \n7      2.202465  6.077300e-07      0      8  \n8      0.000000  8.288700e-07      0      9  \n9      2.021297  2.520400e-06      0     10  \n10     4.717148  1.339900e-06      1     11  \n11     4.862415  1.821000e-06      1     12  \n12     2.618652  8.003800e-07      0     13  \n13     0.000000  5.489100e-07      0     14  \n14     0.000000  3.542700e-06      0     15  \n15     2.369520  2.237000e-06      0     16  \n16     0.000000 -9.999900e+04      0     17  \n17     4.808619  3.827400e-07      1     18  \n18     0.000000  3.391800e-06      0     19  \n19     0.000000  2.676300e-06      0     20  \n20     2.495065  4.372200e-07      0     21  \n21     3.661470  1.841100e-06      0     22  \n22     0.000000  1.524500e-06      0     23  \n23     0.000000  1.724800e-06      0     24  \n24     0.000000  9.518900e-07      0     25  \n25     4.440052  6.065200e-06      0     26  \n26     3.377592  5.184300e-07      1     27  \n27     0.000000  7.784000e-07      0     28  \n28     5.153209  4.608200e-06      1     29  \n29     0.000000  2.122500e-06      0     30  \n...         ...           ...    ...    ...  \n26976  0.000000  8.741900e-07      0  26977  \n26977  0.000000  4.865800e-07      0  26978  \n26978  0.000000  9.755900e-07      0  26979  \n26979  3.974353  4.543800e-07      0  26980  \n26980  4.084673  8.481400e-07      0  26981  \n26981  0.000000  5.603000e-06      0  26982  \n26982  3.364270  1.194700e-06      0  26983  \n26983  0.000000  1.946100e-06      0  26984  \n26984  0.000000 -9.999900e+04      0  26985  \n26985  3.671714  3.326800e-06      0  26986  \n26986  0.000000  1.862300e-06      0  26987  \n26987  4.094562  7.493000e-07      1  26988  \n26988  0.000000  1.636200e-06      0  26989  \n26989  2.413300  1.592300e-06      0  26990  \n26990  5.349037  2.173300e-06      1  26991  \n26991  0.000000  3.931100e-06      0  26992  \n26992  3.157463  9.206000e-07      1  26993  \n26993  0.000000  2.527700e-06      0  26994  \n26994  0.000000  2.028600e-06      0  26995  \n26995  5.068117  9.044900e-07      1  26996  \n26996  2.957113  3.203300e-06      0  26997  \n26997  0.000000  1.086500e-06      0  26998  \n26998  0.000000  9.056400e-07      0  26999  \n26999  0.000000  6.573200e-06      0  27000  \n27000  1.929929  8.033600e-07      0  27001  \n27001  2.398837  7.247600e-07      0  27002  \n27002       NaN  1.043500e-06      0  27003  \n27003  4.063403  9.330800e-07      0  27004  \n27004  0.000000  6.401800e-07      0  27005  \n27005  2.528712  4.609800e-07      0  27006  \n\n[27006 rows x 27 columns]\n"
          ],
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* There are many ways to deal with missing values. The simplest approach would be to drop all rows which contain any missing values."
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "cell_type": "code",
      "source": "df \u003d df.dropna()  # shape: 26666 X 27\nprint(\u0027df.shape \u003d {}\u0027.format(df.shape))",
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "df.shape \u003d (26666, 27)\n"
          ],
          "output_type": "stream"
        }
      ]
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* To train a simple classifier, we first need to have training and validation sets. For simplicity, let\u0027s assign the first two-third of this fold to our training set, and use the rest as a validation set."
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {}
      },
      "cell_type": "code",
      "source": "t \u003d (2/3) * df.shape[0]\ndf_train \u003d df[df[\u0027ID\u0027] \u003c\u003d t]  # shape: 18004 X 27\ndf_val \u003d df[df[\u0027ID\u0027] \u003e t]  # shape: 9002 X 27\nprint(\u0027df_train.shape \u003d {}\u0027.format(df_train.shape))\nprint(\u0027df_val.shape \u003d {}\u0027.format(df_val.shape))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* Finally, time to train a model. Of course, we should import some packages first."
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {}
      },
      "cell_type": "code",
      "source": "from sklearn import svm\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import f1_score",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "**Note** that the training phase may take a few minutes.\n"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "(26666, 27)\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "dfn \u003d df.to_numpy()\nprint(dfn.shape)\nnp.savez(\u0027test.npz\u0027, dfn)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Magnus trying stuff out",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {}
      },
      "cell_type": "code",
      "source": "# Separate values and labels columns\ndf_train_data \u003d df_train.iloc[:, :-2]  # all columns excluding \u0027ID\u0027 and \u0027LABEL\u0027\ndf_train_labels \u003d pd.DataFrame(df_train.LABEL)  # only \u0027LABEL\u0027 column\n\ndf_val_data \u003d df_val.iloc[:, :-2]  # all columns excluding \u0027ID\u0027 and \u0027LABEL\u0027\ndf_val_labels \u003d pd.DataFrame(df_val.LABEL)  # only \u0027LABEL\u0027 column\n\n# Train a simple SVM as an example\nsvm_c \u003d 1000\nsvm_gamma \u003d 0.01\nclf \u003d svm.SVC(gamma\u003dsvm_gamma, C\u003dsvm_c, max_iter\u003d-1, verbose\u003d1, shrinking\u003dTrue, random_state\u003d42)\nclf.fit(df_train_data, np.ravel(df_train_labels))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "* Our model is now ready for prediction. Let\u0027s see how good it performs. (We measure its performance using f1-score)."
    },
    {
      "metadata": {
        "trusted": true,
        "pycharm": {}
      },
      "cell_type": "code",
      "source": "# Test the model against the validation set\npred_labels \u003d clf.predict(df_val_data)\n\n# Evaluate the predictions\nscores \u003d confusion_matrix(df_val_labels, pred_labels).ravel()\ntn, fp, fn, tp \u003d scores\nprint(\u0027TN:{}\\tFP:{}\\tFN:{}\\tTP:{}\u0027.format(tn, fp, fn, tp))\nf1 \u003d f1_score(df_val_labels, pred_labels, average\u003d\u0027binary\u0027, labels\u003d[0, 1])\nprint(\u0027f1-score \u003d {}\u0027.format(f1))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "pycharm": {}
      },
      "cell_type": "markdown",
      "source": "Oops! It seems that the model is not good at all! Maybe the model needs tuning! Maybe the data needs more preprocessing! Or, maybe the \"last values\", as we used in this example code, is not such a good predicator for solar flares!\n#### You can pick up from here. It\u0027s all in your hands now."
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}