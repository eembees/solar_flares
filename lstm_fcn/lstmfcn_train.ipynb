{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"lstmfcn_train.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"language_info":{"codemirror_mode":{"name":"ipython","version":2},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython2","version":"2.7.6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"pycharm":{},"id":"OqLgZ65VuHev","colab_type":"code","colab":{}},"source":["%%capture\n","!pip3 install ijson\n","!pip3 install json\n","!pip3 install send2trash\n","from google.colab import drive, files\n","drive.mount('/content/gdrive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"pycharm":{"metadata":false,"name":"#%%\n"},"id":"YGw3l4ehuHey","colab_type":"code","outputId":"2003140e-13de-49ec-8459-3e56eba6c915","executionInfo":{"status":"ok","timestamp":1557243534707,"user_tz":-120,"elapsed":15861,"user":{"displayName":"Magnus Berg Sletfjerding","photoUrl":"https://lh4.googleusercontent.com/-kOsLnPwROXs/AAAAAAAAAAI/AAAAAAAADkE/S4j23z8F9ZY/s64/photo.jpg","userId":"14713142134582708612"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import sys\n","import matplotlib.pyplot as plt\n","import keras\n","import tensorflow\n","import pandas as pd\n","from keras.layers import *\n","from pathlib import Path\n","from sklearn.metrics import f1_score\n","\n","\n","\n","np.set_printoptions(edgeitems=30, linewidth=100000, formatter=dict(float=lambda x: \"%.3g\" % x))\n","GOOGLE_COLAB = \"google.colab\" in sys.modules\n","if GOOGLE_COLAB:\n","    sys.path.append(\"./gdrive/My Drive/Colab Notebooks/solar_flares\")\n","    plt.style.use(\"default\")\n","    config = tensorflow.ConfigProto(device_count={\"GPU\": 1})\n","    keras.backend.set_session(tensorflow.Session(config=config))\n","    from lstm_fcn.lstmfcn_model import *\n","    from reading_data import load_npz_file\n","\n","\n","else:\n","    config = tensorflow.ConfigProto(intra_op_parallelism_threads=8, inter_op_parallelism_threads=8)\n","    keras.backend.tensorflow_backend.set_session(tensorflow.Session(config=config))\n","    from lstm_fcn.lstmfcn_model import *\n","    from reading_data import load_npz_file\n","\n","\n","\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"pycharm":{"metadata":false,"name":"#%%\n"},"id":"MZraEhxbuHe1","colab_type":"code","outputId":"c7013b6c-584c-4aab-f5e3-69637bd2ce47","executionInfo":{"status":"ok","timestamp":1557246297767,"user_tz":-120,"elapsed":799104,"user":{"displayName":"Magnus Berg Sletfjerding","photoUrl":"https://lh4.googleusercontent.com/-kOsLnPwROXs/AAAAAAAAAAI/AAAAAAAADkE/S4j23z8F9ZY/s64/photo.jpg","userId":"14713142134582708612"}},"colab":{"base_uri":"https://localhost:8080/","height":4576}},"source":["if __name__ == '__main__':\n","    ROOTDIR = \"/Users/mag/Google Drive/Colab Notebooks/solar_flares/\"\n","    DATADIR = \"input/npz\"\n","    OUTDIR = \"output\"\n","    DATANAME = \"lstm_fcn\"\n","    TAG = None\n","    \n","    TRAIN = True\n","    NEW_MODEL = True\n","\n","    TEST = False\n","\n","    CALLBACK_TIMEOUT = 15\n","    N_TIMESTEPS = 60  # Change if Variable length\n","    INCLUDE_E = True\n","    INCLUDE_S = True\n","    SCALER = sklearn.preprocessing.maxabs_scale\n","    STATIONARY = False\n","    if TEST:\n","        model_name = \"{}_test_model.h5\".format(DATANAME)\n","        EPOCHS = 10\n","        PERCENTAGE = 100\n","        BATCH_SIZE = 128\n","    else:\n","        model_name = \"{}_best_model.h5\".format(DATANAME)\n","        EPOCHS = 100\n","        PERCENTAGE = 100\n","        BATCH_SIZE = 32\n","\n","    if GOOGLE_COLAB:\n","        ROOTDIR = \"./gdrive/My Drive/Colab Notebooks\" + str(ROOTDIR).split(\"Colab Notebooks\")[-1]\n","\n","    rootdir = Path(ROOTDIR)\n","    datadir = rootdir.joinpath(DATADIR)\n","    outdir = rootdir.joinpath(OUTDIR)\n","\n","\n","\n","    if TEST:\n","        X, y = load_npz_file(datadir / 'fold2Training.npz')\n","    else:\n","        X1, y1 = load_npz_file(datadir / 'fold1Training.npz')\n","        X2, y2 = load_npz_file(datadir / 'fold2Training.npz')\n","        X3, y3 = load_npz_file(datadir / 'fold3Training.npz')\n","\n","        X = np.concatenate([X1, X2, X3])\n","        y = np.concatenate([y1, y2, y3])\n","        \n","    print(\"Data loaded.\")\n","    \n","    y = keras.utils.to_categorical(y, num_classes=2)\n","\n","    # preprocess x\n","\n","    X = sklearn.preprocessing.StandardScaler().fit_transform(X.reshape((X.shape[0], X.shape[1]*X.shape[2]))).reshape(X.shape)\n","\n","\n","    X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n","        X, y,\n","        train_size = 0.9\n","        )\n","\n","    del X\n","    del y\n","    \n","    \n","    model = get_model(\n","        n_features=X_train.shape[-1],\n","        train=TRAIN,\n","        new_model=NEW_MODEL,\n","        model_name=model_name,\n","        model_path=outdir,\n","        google_colab=GOOGLE_COLAB,\n","    )\n","\n","    # if TAG is not None:\n","    #     DATANAME += \"_\" + TAG\n","    #     model_name = model_name.replace(\"best_model\", TAG + \"_best_model\")\n","\n","    if TRAIN:\n","        callbacks = generate_callbacks(patience=CALLBACK_TIMEOUT, outdir=outdir, name=DATANAME)\n","\n","        model.fit(\n","            x=X_train,\n","            y=y_train,\n","            validation_data=(X_test, y_test),\n","            epochs=EPOCHS,\n","            batch_size=BATCH_SIZE,\n","            callbacks=callbacks,\n","        )\n","        # lib.plotting.plot_losses(logpath=outdir, outdir=outdir, name=DATANAME)\n","\n","        if GOOGLE_COLAB:\n","            print(\"Converted model from GPU to CPU-compatible\")\n","            cpu_model = create_model(google_colab=False, n_features=X_train.shape[-1])\n","            gpu_model_to_cpu(\n","                trained_gpu_model=model, untrained_cpu_model=cpu_model, outdir=outdir, modelname=model_name\n","            )\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Data loaded.\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n","  FutureWarning)\n"],"name":"stderr"},{"output_type":"stream","text":["Created new model.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Colocations handled automatically by placer.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, None, 25)     0                                            \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, None, 128)    25728       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, None, 128)    512         conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, None, 128)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","spatial_dropout1d_1 (SpatialDro (None, None, 128)    0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, None, 256)    164096      spatial_dropout1d_1[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, None, 256)    1024        conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, None, 256)    0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","spatial_dropout1d_2 (SpatialDro (None, None, 256)    0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","conv1d_3 (Conv1D)               (None, None, 128)    98432       spatial_dropout1d_2[0][0]        \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, None, 128)    512         conv1d_3[0][0]                   \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, None, 128)    0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","spatial_dropout1d_3 (SpatialDro (None, None, 128)    0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","average_pooling1d_2 (AveragePoo (None, None, 25)     0           input_1[0][0]                    \n","__________________________________________________________________________________________________\n","average_pooling1d_1 (AveragePoo (None, None, 128)    0           spatial_dropout1d_3[0][0]        \n","__________________________________________________________________________________________________\n","bidirectional_2 (Bidirectional) (None, 16)           2240        average_pooling1d_2[0][0]        \n","__________________________________________________________________________________________________\n","bidirectional_1 (Bidirectional) (None, 16)           8832        average_pooling1d_1[0][0]        \n","__________________________________________________________________________________________________\n","dropout_2 (Dropout)             (None, 16)           0           bidirectional_2[0][0]            \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 16)           0           bidirectional_1[0][0]            \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 32)           0           dropout_2[0][0]                  \n","                                                                 dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2)            66          concatenate_1[0][0]              \n","==================================================================================================\n","Total params: 301,442\n","Trainable params: 300,418\n","Non-trainable params: 1,024\n","__________________________________________________________________________________________________\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Train on 176634 samples, validate on 19626 samples\n","Epoch 1/100\n","176634/176634 [==============================] - 33s 189us/step - loss: 0.2601 - acc: 0.8832 - val_loss: 0.2395 - val_acc: 0.8923\n","Epoch 2/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.2393 - acc: 0.8915 - val_loss: 0.2332 - val_acc: 0.8947\n","Epoch 3/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.2340 - acc: 0.8941 - val_loss: 0.2302 - val_acc: 0.8978\n","Epoch 4/100\n","176634/176634 [==============================] - 26s 148us/step - loss: 0.2302 - acc: 0.8962 - val_loss: 0.2263 - val_acc: 0.8989\n","Epoch 5/100\n","176634/176634 [==============================] - 26s 150us/step - loss: 0.2271 - acc: 0.8973 - val_loss: 0.2238 - val_acc: 0.9007\n","Epoch 6/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.2250 - acc: 0.8982 - val_loss: 0.2214 - val_acc: 0.9008\n","Epoch 7/100\n","176634/176634 [==============================] - 26s 148us/step - loss: 0.2224 - acc: 0.8994 - val_loss: 0.2210 - val_acc: 0.8997\n","Epoch 8/100\n","176634/176634 [==============================] - 26s 150us/step - loss: 0.2201 - acc: 0.9005 - val_loss: 0.2158 - val_acc: 0.9033\n","Epoch 9/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.2183 - acc: 0.9019 - val_loss: 0.2157 - val_acc: 0.9045\n","Epoch 10/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.2160 - acc: 0.9029 - val_loss: 0.2096 - val_acc: 0.9057\n","Epoch 11/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.2142 - acc: 0.9039 - val_loss: 0.2088 - val_acc: 0.9074\n","Epoch 12/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.2117 - acc: 0.9048 - val_loss: 0.2061 - val_acc: 0.9092\n","Epoch 13/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.2092 - acc: 0.9063 - val_loss: 0.2011 - val_acc: 0.9101\n","Epoch 14/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.2067 - acc: 0.9071 - val_loss: 0.1985 - val_acc: 0.9126\n","Epoch 15/100\n","176634/176634 [==============================] - 26s 149us/step - loss: 0.2047 - acc: 0.9090 - val_loss: 0.1978 - val_acc: 0.9119\n","Epoch 16/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.2028 - acc: 0.9104 - val_loss: 0.1939 - val_acc: 0.9138\n","Epoch 17/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.2019 - acc: 0.9103 - val_loss: 0.1914 - val_acc: 0.9139\n","Epoch 18/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.1999 - acc: 0.9114 - val_loss: 0.1908 - val_acc: 0.9137\n","Epoch 19/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.2008 - acc: 0.9106 - val_loss: 0.1918 - val_acc: 0.9154\n","Epoch 20/100\n","176634/176634 [==============================] - 26s 150us/step - loss: 0.1974 - acc: 0.9131 - val_loss: 0.1887 - val_acc: 0.9177\n","Epoch 21/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1971 - acc: 0.9126 - val_loss: 0.1844 - val_acc: 0.9184\n","Epoch 22/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1945 - acc: 0.9135 - val_loss: 0.1819 - val_acc: 0.9186\n","Epoch 23/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1926 - acc: 0.9152 - val_loss: 0.1791 - val_acc: 0.9214\n","Epoch 24/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1916 - acc: 0.9154 - val_loss: 0.1767 - val_acc: 0.9202\n","Epoch 25/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1905 - acc: 0.9161 - val_loss: 0.1768 - val_acc: 0.9237\n","Epoch 26/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1892 - acc: 0.9166 - val_loss: 0.1757 - val_acc: 0.9226\n","Epoch 27/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1887 - acc: 0.9172 - val_loss: 0.1725 - val_acc: 0.9238\n","Epoch 28/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1860 - acc: 0.9179 - val_loss: 0.1691 - val_acc: 0.9249\n","Epoch 29/100\n","176634/176634 [==============================] - 28s 160us/step - loss: 0.1846 - acc: 0.9185 - val_loss: 0.1687 - val_acc: 0.9256\n","Epoch 30/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1837 - acc: 0.9201 - val_loss: 0.1639 - val_acc: 0.9303\n","Epoch 31/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1808 - acc: 0.9208 - val_loss: 0.1626 - val_acc: 0.9307\n","Epoch 32/100\n","176634/176634 [==============================] - 28s 159us/step - loss: 0.1804 - acc: 0.9209 - val_loss: 0.1610 - val_acc: 0.9314\n","Epoch 33/100\n","176634/176634 [==============================] - 27s 156us/step - loss: 0.1802 - acc: 0.9210 - val_loss: 0.1587 - val_acc: 0.9305\n","Epoch 34/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1770 - acc: 0.9227 - val_loss: 0.1597 - val_acc: 0.9300\n","Epoch 35/100\n","176634/176634 [==============================] - 28s 159us/step - loss: 0.1790 - acc: 0.9214 - val_loss: 0.1613 - val_acc: 0.9293\n","Epoch 36/100\n","176634/176634 [==============================] - 27s 155us/step - loss: 0.1766 - acc: 0.9225 - val_loss: 0.1568 - val_acc: 0.9295\n","Epoch 37/100\n","176634/176634 [==============================] - 28s 157us/step - loss: 0.1751 - acc: 0.9234 - val_loss: 0.1530 - val_acc: 0.9348\n","Epoch 38/100\n","176634/176634 [==============================] - 28s 158us/step - loss: 0.1721 - acc: 0.9247 - val_loss: 0.1494 - val_acc: 0.9354\n","Epoch 39/100\n","176634/176634 [==============================] - 27s 155us/step - loss: 0.1719 - acc: 0.9248 - val_loss: 0.1477 - val_acc: 0.9379\n","Epoch 40/100\n","176634/176634 [==============================] - 27s 154us/step - loss: 0.1701 - acc: 0.9261 - val_loss: 0.1474 - val_acc: 0.9373\n","Epoch 41/100\n","176634/176634 [==============================] - 26s 149us/step - loss: 0.1689 - acc: 0.9263 - val_loss: 0.1478 - val_acc: 0.9377\n","Epoch 42/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1680 - acc: 0.9270 - val_loss: 0.1478 - val_acc: 0.9400\n","Epoch 43/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1674 - acc: 0.9271 - val_loss: 0.1436 - val_acc: 0.9395\n","Epoch 44/100\n","176634/176634 [==============================] - 28s 157us/step - loss: 0.1664 - acc: 0.9282 - val_loss: 0.1418 - val_acc: 0.9396\n","Epoch 45/100\n","176634/176634 [==============================] - 27s 155us/step - loss: 0.1645 - acc: 0.9289 - val_loss: 0.1395 - val_acc: 0.9419\n","Epoch 46/100\n","176634/176634 [==============================] - 28s 157us/step - loss: 0.1632 - acc: 0.9295 - val_loss: 0.1377 - val_acc: 0.9427\n","Epoch 47/100\n","176634/176634 [==============================] - 27s 155us/step - loss: 0.1636 - acc: 0.9295 - val_loss: 0.1369 - val_acc: 0.9424\n","Epoch 48/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1640 - acc: 0.9287 - val_loss: 0.1375 - val_acc: 0.9428\n","Epoch 49/100\n","176634/176634 [==============================] - 26s 149us/step - loss: 0.1623 - acc: 0.9302 - val_loss: 0.1371 - val_acc: 0.9427\n","Epoch 50/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1623 - acc: 0.9299 - val_loss: 0.1345 - val_acc: 0.9437\n","Epoch 51/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1596 - acc: 0.9310 - val_loss: 0.1328 - val_acc: 0.9433\n","Epoch 52/100\n","176634/176634 [==============================] - 27s 153us/step - loss: 0.1605 - acc: 0.9298 - val_loss: 0.1330 - val_acc: 0.9427\n","Epoch 53/100\n","176634/176634 [==============================] - 26s 145us/step - loss: 0.1583 - acc: 0.9313 - val_loss: 0.1303 - val_acc: 0.9463\n","Epoch 54/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1562 - acc: 0.9319 - val_loss: 0.1308 - val_acc: 0.9445\n","Epoch 55/100\n","176634/176634 [==============================] - 26s 148us/step - loss: 0.1546 - acc: 0.9344 - val_loss: 0.1267 - val_acc: 0.9492\n","Epoch 56/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1555 - acc: 0.9332 - val_loss: 0.1247 - val_acc: 0.9477\n","Epoch 57/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1533 - acc: 0.9344 - val_loss: 0.1260 - val_acc: 0.9483\n","Epoch 58/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1535 - acc: 0.9345 - val_loss: 0.1216 - val_acc: 0.9504\n","Epoch 59/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1530 - acc: 0.9346 - val_loss: 0.1253 - val_acc: 0.9474\n","Epoch 60/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1521 - acc: 0.9353 - val_loss: 0.1223 - val_acc: 0.9502\n","Epoch 61/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1508 - acc: 0.9358 - val_loss: 0.1241 - val_acc: 0.9490\n","Epoch 62/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1514 - acc: 0.9349 - val_loss: 0.1245 - val_acc: 0.9499\n","Epoch 63/100\n","176634/176634 [==============================] - 26s 147us/step - loss: 0.1483 - acc: 0.9369 - val_loss: 0.1184 - val_acc: 0.9529\n","Epoch 64/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1479 - acc: 0.9364 - val_loss: 0.1196 - val_acc: 0.9519\n","Epoch 65/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1456 - acc: 0.9381 - val_loss: 0.1167 - val_acc: 0.9525\n","Epoch 66/100\n","176634/176634 [==============================] - 26s 145us/step - loss: 0.1467 - acc: 0.9377 - val_loss: 0.1156 - val_acc: 0.9540\n","Epoch 67/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1468 - acc: 0.9377 - val_loss: 0.1195 - val_acc: 0.9514\n","Epoch 68/100\n","176634/176634 [==============================] - 26s 148us/step - loss: 0.1465 - acc: 0.9379 - val_loss: 0.1149 - val_acc: 0.9540\n","Epoch 69/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1452 - acc: 0.9388 - val_loss: 0.1125 - val_acc: 0.9550\n","Epoch 70/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1444 - acc: 0.9396 - val_loss: 0.1122 - val_acc: 0.9547\n","Epoch 71/100\n","176634/176634 [==============================] - 30s 172us/step - loss: 0.1427 - acc: 0.9400 - val_loss: 0.1146 - val_acc: 0.9542\n","Epoch 72/100\n","176634/176634 [==============================] - 28s 157us/step - loss: 0.1408 - acc: 0.9411 - val_loss: 0.1142 - val_acc: 0.9529\n","Epoch 73/100\n","176634/176634 [==============================] - 28s 160us/step - loss: 0.1411 - acc: 0.9404 - val_loss: 0.1119 - val_acc: 0.9542\n","Epoch 74/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1394 - acc: 0.9409 - val_loss: 0.1097 - val_acc: 0.9575\n","Epoch 75/100\n","176634/176634 [==============================] - 28s 161us/step - loss: 0.1397 - acc: 0.9409 - val_loss: 0.1130 - val_acc: 0.9539\n","Epoch 76/100\n","176634/176634 [==============================] - 28s 160us/step - loss: 0.1425 - acc: 0.9397 - val_loss: 0.1106 - val_acc: 0.9568\n","Epoch 77/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1417 - acc: 0.9403 - val_loss: 0.1083 - val_acc: 0.9578\n","Epoch 78/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1413 - acc: 0.9400 - val_loss: 0.1078 - val_acc: 0.9581\n","Epoch 79/100\n","176634/176634 [==============================] - 28s 159us/step - loss: 0.1386 - acc: 0.9416 - val_loss: 0.1054 - val_acc: 0.9576\n","Epoch 80/100\n","176634/176634 [==============================] - 28s 156us/step - loss: 0.1382 - acc: 0.9417 - val_loss: 0.1075 - val_acc: 0.9572\n","Epoch 81/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.1379 - acc: 0.9419 - val_loss: 0.1063 - val_acc: 0.9576\n","Epoch 82/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.1368 - acc: 0.9430 - val_loss: 0.1055 - val_acc: 0.9590\n","Epoch 83/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1359 - acc: 0.9432 - val_loss: 0.1044 - val_acc: 0.9581\n","Epoch 84/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1332 - acc: 0.9444 - val_loss: 0.1007 - val_acc: 0.9609\n","Epoch 85/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.1355 - acc: 0.9436 - val_loss: 0.1035 - val_acc: 0.9593\n","Epoch 86/100\n","176634/176634 [==============================] - 27s 151us/step - loss: 0.1340 - acc: 0.9440 - val_loss: 0.1018 - val_acc: 0.9605\n","Epoch 87/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1325 - acc: 0.9449 - val_loss: 0.1009 - val_acc: 0.9601\n","Epoch 88/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1342 - acc: 0.9437 - val_loss: 0.1016 - val_acc: 0.9608\n","Epoch 89/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1332 - acc: 0.9445 - val_loss: 0.1015 - val_acc: 0.9603\n","Epoch 90/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1249 - acc: 0.9486 - val_loss: 0.0936 - val_acc: 0.9635\n","Epoch 91/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1234 - acc: 0.9495 - val_loss: 0.0915 - val_acc: 0.9650\n","Epoch 92/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1205 - acc: 0.9505 - val_loss: 0.0897 - val_acc: 0.9656\n","Epoch 93/100\n","176634/176634 [==============================] - 26s 148us/step - loss: 0.1190 - acc: 0.9510 - val_loss: 0.0889 - val_acc: 0.9655\n","Epoch 94/100\n","176634/176634 [==============================] - 27s 150us/step - loss: 0.1184 - acc: 0.9517 - val_loss: 0.0882 - val_acc: 0.9658\n","Epoch 95/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1194 - acc: 0.9508 - val_loss: 0.0877 - val_acc: 0.9659\n","Epoch 96/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1164 - acc: 0.9524 - val_loss: 0.0872 - val_acc: 0.9657\n","Epoch 97/100\n","176634/176634 [==============================] - 26s 150us/step - loss: 0.1153 - acc: 0.9527 - val_loss: 0.0863 - val_acc: 0.9656\n","Epoch 98/100\n","176634/176634 [==============================] - 27s 152us/step - loss: 0.1163 - acc: 0.9523 - val_loss: 0.0865 - val_acc: 0.9657\n","Epoch 99/100\n","176634/176634 [==============================] - 26s 146us/step - loss: 0.1147 - acc: 0.9532 - val_loss: 0.0869 - val_acc: 0.9658\n","Epoch 100/100\n","176634/176634 [==============================] - 26s 150us/step - loss: 0.1148 - acc: 0.9529 - val_loss: 0.0860 - val_acc: 0.9662\n","Converted model from GPU to CPU-compatible\n"],"name":"stdout"},{"output_type":"stream","text":["./gdrive/My Drive/Colab Notebooks/solar_flares/lstm_fcn/lstmfcn_model.py:147: RuntimeWarning: Didn't trash file (probably because of Google Drive)\n","  warn(\"Didn't trash file (probably because of Google Drive)\", RuntimeWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"iyRZU4AON0KE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"outputId":"ab44fca4-feed-487f-826c-4316706c8329","executionInfo":{"status":"ok","timestamp":1557246303288,"user_tz":-120,"elapsed":5527,"user":{"displayName":"Magnus Berg Sletfjerding","photoUrl":"https://lh4.googleusercontent.com/-kOsLnPwROXs/AAAAAAAAAAI/AAAAAAAADkE/S4j23z8F9ZY/s64/photo.jpg","userId":"14713142134582708612"}}},"source":["    print(\"Evaluating...\")\n","    y_pred = model.predict(X_test)\n","\n","\n","\n","    #for yp, yt in zip(np.argmax(y_pred, axis=1), np.argmax(y_test, axis=1)):\n","    #    print('T:{} P:{}'.format(yt,yp))\n","    plot_confusion_matrices(\n","        y_target=np.argmax(y_test,axis=1), y_pred=np.argmax(y_pred,axis=1), y_is_binary=True, outdir=outdir, name=DATANAME\n","    )\n","    print(\"F1 score: {}\".format(f1_score(np.argmax(y_test,axis=1), np.argmax(y_pred,axis=1))))\n","    # \n","    # df = pd.DataFrame({'Id':ids,'ClassLabel':np.argmax(y_pred,axis=1)})\n","    # df.to_csv(outdir/'submission.csv')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Evaluating...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/mlxtend/plotting/plot_confusion_matrix.py:59: RuntimeWarning: invalid value encountered in true_divide\n","  normed_conf_mat = conf_mat.astype('float') / total_samples\n"],"name":"stderr"},{"output_type":"stream","text":["F1 score: 0.8947451976504206\n"],"name":"stdout"}]}]}