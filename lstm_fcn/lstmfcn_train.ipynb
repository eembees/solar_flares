{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "pycharm": {}
      },
      "outputs": [],
      "source": "%%capture\n\nfrom google.colab import drive, files\ndrive.mount(\u0027/content/gdrive\u0027, force_remount\u003dTrue)"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "import sys\nimport matplotlib.pyplot as plt\nimport keras\nimport tensorflow\nimport pandas as pd\nfrom keras.layers import *\nfrom pathlib import Path\n\nfrom lstm_fcn.lstmfcn_model import *\nfrom reading_data import load_npz_file\n\n\nnp.set_printoptions(edgeitems\u003d30, linewidth\u003d100000, formatter\u003ddict(float\u003dlambda x: \"%.3g\" % x))\nGOOGLE_COLAB \u003d \"google.colab\" in sys.modules\nif GOOGLE_COLAB:\n    sys.path.append(\"./gdrive/My Drive/Colab Notebooks/FRETML\")\n    plt.style.use(\"default\")\n    config \u003d tensorflow.ConfigProto(device_count\u003d{\"GPU\": 1})\n    keras.backend.set_session(tensorflow.Session(config\u003dconfig))\nelse:\n    config \u003d tensorflow.ConfigProto(intra_op_parallelism_threads\u003d8, inter_op_parallelism_threads\u003d8)\n    keras.backend.tensorflow_backend.set_session(tensorflow.Session(config\u003dconfig))\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "if __name__ \u003d\u003d \u0027__main__\u0027:\n    ROOTDIR \u003d \"/Users/mag/Google Drive/Colab Notebooks/solar_flares/\"\n    DATADIR \u003d \"input/npz\"\n    OUTDIR \u003d \"output\"\n    DATANAME \u003d \"lstm_fcn\"\n    TAG \u003d \"spatialdropout\"\n\n    TRAIN \u003d True\n    NEW_MODEL \u003d True\n\n    TEST \u003d False\n\n    EPOCHS \u003d 10\n    PERCENTAGE \u003d 100\n    BATCH_SIZE \u003d 128\n    CALLBACK_TIMEOUT \u003d 15\n    N_TIMESTEPS \u003d 60  # Change if Variable length\n    INCLUDE_E \u003d True\n    INCLUDE_S \u003d True\n    SCALER \u003d sklearn.preprocessing.maxabs_scale\n    STATIONARY \u003d False\n\n    model_name \u003d \"{}_best_model.h5\".format(DATANAME)\n    if GOOGLE_COLAB:\n        ROOTDIR \u003d \"./gdrive/My Drive/Colab Notebooks\" + str(ROOTDIR).split(\"Colab Notebooks\")[-1]\n\n    rootdir \u003d Path(ROOTDIR)\n    datadir \u003d rootdir.joinpath(DATADIR)\n    outdir \u003d rootdir.joinpath(OUTDIR)\n\n\n\n    if TEST:\n        X, y \u003d load_npz_file(datadir / \u0027small.npz\u0027)\n    else:\n        X1, y1 \u003d load_npz_file(datadir / \u0027fold1Training.npz\u0027)\n        X2, y2 \u003d load_npz_file(datadir / \u0027fold2Training.npz\u0027)\n        X3, y3 \u003d load_npz_file(datadir / \u0027fold3Training.npz\u0027)\n\n        X \u003d np.concatenate([X1, X2, X3])\n        y \u003d np.concatenate([y1, y2, y3])\n        \n\n    y \u003d keras.utils.to_categorical(y, num_classes\u003d2)\n\n    # preprocess x\n\n    X \u003d sklearn.preprocessing.StandardScaler().fit_transform(X.reshape((X.shape[0], X.shape[1]*X.shape[2]))).reshape(X.shape)\n\n\n    X_train, X_test, y_train, y_test \u003d sklearn.model_selection.train_test_split(\n        X, y)\n\n    model \u003d get_model(\n        n_features\u003dX_train.shape[-1],\n        train\u003dTRAIN,\n        new_model\u003dNEW_MODEL,\n        model_name\u003dmodel_name,\n        model_path\u003doutdir,\n        google_colab\u003dGOOGLE_COLAB,\n    )\n\n    # if TAG is not None:\n    #     DATANAME +\u003d \"_\" + TAG\n    #     model_name \u003d model_name.replace(\"best_model\", TAG + \"_best_model\")\n\n    if TRAIN:\n        callbacks \u003d generate_callbacks(patience\u003dCALLBACK_TIMEOUT, outdir\u003doutdir, name\u003dDATANAME)\n        model.fit(\n            x\u003dX_train,\n            y\u003dy_train,\n            validation_data\u003d(X_test, y_test),\n            epochs\u003dEPOCHS,\n            batch_size\u003dBATCH_SIZE,\n            callbacks\u003dcallbacks,\n        )\n        # lib.plotting.plot_losses(logpath\u003doutdir, outdir\u003doutdir, name\u003dDATANAME)\n\n        if GOOGLE_COLAB:\n            print(\"Converted model from GPU to CPU-compatible\")\n            cpu_model \u003d create_model(google_colab\u003dFalse, n_features\u003dX_train.shape[-1])\n            gpu_model_to_cpu(\n                trained_gpu_model\u003dmodel, untrained_cpu_model\u003dcpu_model, outdir\u003doutdir, modelname\u003dmodel_name\n            )\n\n    print(\"Evaluating...\")\n    y_pred \u003d model.predict(X_test)\n\n\n\n    for yp, yt in zip(np.argmax(y_pred, axis\u003d1), np.argmax(y_test, axis\u003d1)):\n        print(\u0027T:{} P:{}\u0027.format(yt,yp))\n\n    plot_confusion_matrices(\n        y_target\u003dnp.argmax(y_test,axis\u003d1), y_pred\u003dnp.argmax(y_pred,axis\u003d1), y_is_binary\u003dTrue, outdir\u003doutdir, name\u003dDATANAME\n    )\n\n    # \n    # df \u003d pd.DataFrame({\u0027Id\u0027:ids,\u0027ClassLabel\u0027:np.argmax(y_pred,axis\u003d1)})\n    # df.to_csv(outdir/\u0027submission.csv\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}